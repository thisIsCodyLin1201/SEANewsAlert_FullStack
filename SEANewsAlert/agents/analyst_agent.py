"""
Analyst Agent
è² è²¬å°‡æœå°‹çµæœçµæ§‹åŒ–ä¸¦æ•´ç†æˆå°ˆæ¥­å ±å‘Š
"""
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from config import Config
from typing import Dict, Any, List, Tuple
from datetime import datetime
import json
import re


class AnalystAgent:
    """åˆ†æä»£ç† - å°‡åŸå§‹æœå°‹çµæœæ•´ç†æˆçµæ§‹åŒ–å ±å‘Š"""
    
    def __init__(self):
        """åˆå§‹åŒ– Analyst Agent"""
        self.agent = Agent(
            name="é‡‘èæ–°èåˆ†æå¸«",
            model=OpenAIChat(
                id=Config.OPENAI_MODEL,
                api_key=Config.OPENAI_API_KEY,
                # max_tokens=4096,  # å¢åŠ è¼¸å‡º token é™åˆ¶ï¼Œå…è¨±æ›´è©³ç´°çš„å ±å‘Š
            ),
            description="å°ˆæ¥­çš„é‡‘èæ–°èåˆ†æå¸«ï¼Œæ“…é•·æ•´ç†å’Œçµæ§‹åŒ–è³‡è¨Š",
            instructions=[
                "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„é‡‘èåˆ†æå¸«ï¼Œè² è²¬æ•´ç†æ–°èè³‡è¨Š",
                "å°‡æœå°‹çµæœæ•´ç†æˆæ¸…æ™°ã€å°ˆæ¥­çš„ç¹é«”ä¸­æ–‡å ±å‘Š",
                "å ±å‘Šçµæ§‹æ‡‰åŒ…å«ï¼šæ¨™é¡Œã€æ‘˜è¦ã€è©³ç´°å…§å®¹ã€è³‡æ–™ä¾†æº",
                "ä½¿ç”¨ Markdown æ ¼å¼è¼¸å‡º",
                "æ¯æ¢æ–°èéƒ½è¦é™„ä¸Šä¾†æºè¶…é€£çµ",
                "å»é™¤é‡è¤‡å’Œå†—é¤˜è³‡è¨Š",
                "æŒ‰ç…§é‡è¦æ€§å’Œæ™‚é–“é †åºæ’åˆ—",
                "ä½¿ç”¨å°ˆæ¥­ä½†æ˜“æ‡‚çš„èªè¨€",
                "æä¾›è©³ç´°ä¸”æ·±å…¥çš„åˆ†æï¼Œä¸è¦éæ–¼ç°¡çŸ­",
                "æ¯æ¢æ–°èçš„æ‘˜è¦æ‡‰è©²è©³ç´°å®Œæ•´ï¼Œè‡³å°‘ 150-300 å­—",
                "å¸‚å ´æ´å¯Ÿéƒ¨åˆ†æ‡‰è©²æä¾› 5-8 é»æ·±å…¥çš„åˆ†æ"
            ],
            markdown=True,
        )
    
    def analyze(self, search_results: Dict[str, Any]) -> Tuple[str, List[Dict[str, str]]]:
        """
        åˆ†æä¸¦çµæ§‹åŒ–æœå°‹çµæœ
        
        Args:
            search_results: ä¾†è‡ª Research Agent çš„æœå°‹çµæœ
            
        Returns:
            Tuple[str, List[Dict]]: (Markdown æ ¼å¼çš„å ±å‘Š, çµæ§‹åŒ–æ–°èåˆ—è¡¨)
        """
        print("ğŸ“Š Analyst Agent é–‹å§‹åˆ†æ...")
        
        # æå–æœå°‹å…§å®¹
        content = search_results.get("content", "")
        query = search_results.get("query", "")
        
        # æ§‹å»ºåˆ†ææç¤º
        analysis_prompt = f"""
        è«‹å°‡ä»¥ä¸‹æœå°‹çµæœæ•´ç†æˆä¸€ä»½å°ˆæ¥­çš„ç¹é«”ä¸­æ–‡é‡‘èå ±å‘Šã€‚
        
        åŸå§‹æŸ¥è©¢ï¼š{query}
        æœå°‹çµæœï¼š
        {content}
        
        **é‡è¦**ï¼šä½ å¿…é ˆåš´æ ¼éµå¾ªä»¥ä¸‹æ ¼å¼ï¼Œæ¯å‰‡æ–°èéƒ½å¿…é ˆåŒ…å«ã€Œä¾†æºã€ã€ã€Œæ—¥æœŸã€ã€ã€Œæ‘˜è¦ã€ã€ã€Œé‡é»åˆ†æã€å››å€‹æ¬„ä½ï¼Œä¸”ä½¿ç”¨ **ç²—é«”æ¨™è¨˜**ã€‚
        
        å ±å‘Šæ ¼å¼è¦æ±‚ï¼š
        
        # æ±å—äºé‡‘èæ–°èå ±å‘Š
        
        ## å ±å‘Šæ‘˜è¦
        [ç”¨ 2-3 å¥è©±ç¸½çµæœ¬å ±å‘Šçš„æ ¸å¿ƒå…§å®¹]
        
        ## æœå°‹ä¸»é¡Œ
        {query}
        
        ## å ±å‘Šæ—¥æœŸ
        {datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")}
        
        ## æ–°èè©³æƒ…
        
        ### 1. [æ–°èæ¨™é¡Œç¿»è­¯æˆç¹é«”ä¸­æ–‡]
        - **ä¾†æº**ï¼š[ä¾†æºåç¨±]([ç¶²å€])
        - **æ—¥æœŸ**ï¼š[YYYY-MM-DD æ ¼å¼]
        - **æ‘˜è¦**ï¼š[æ–°èçš„è©³ç´°æ‘˜è¦ï¼Œ100-300å­—ï¼Œèªªæ˜æ–°èçš„ä¸»è¦å…§å®¹]
        - **é‡é»åˆ†æ**ï¼š[é—œéµè³‡è¨Šçš„æ¢åˆ—å¼åˆ†æï¼Œç”¨ 1) 2) 3) ç·¨è™Ÿ]
        
        ### 2. [æ–°èæ¨™é¡Œç¿»è­¯æˆç¹é«”ä¸­æ–‡]
        - **ä¾†æº**ï¼š[ä¾†æºåç¨±]([ç¶²å€])
        - **æ—¥æœŸ**ï¼š[YYYY-MM-DD æ ¼å¼]
        - **æ‘˜è¦**ï¼š[æ–°èçš„è©³ç´°æ‘˜è¦ï¼Œ100-300å­—ï¼Œèªªæ˜æ–°èçš„ä¸»è¦å…§å®¹]
        - **é‡é»åˆ†æ**ï¼š[é—œéµè³‡è¨Šçš„æ¢åˆ—å¼åˆ†æï¼Œç”¨ 1) 2) 3) ç·¨è™Ÿ]
        
        ï¼ˆæ¯å‰‡æ–°èéƒ½æŒ‰ç…§ä¸Šè¿°æ ¼å¼ï¼Œä¸è¦çœç•¥ä»»ä½•æ¬„ä½ï¼‰
        
        ## å¸‚å ´æ´å¯Ÿ
        [åŸºæ–¼ä»¥ä¸Šæ–°èï¼Œæä¾› 3-5 é»é—œéµæ´å¯Ÿ]
        
        ## è³‡æ–™ä¾†æº
        - [ä¾†æº1æ¨™é¡Œ](ç¶²å€)
        - [ä¾†æº2æ¨™é¡Œ](ç¶²å€)
        ...
        
        ---
        **å ±å‘Šç”Ÿæˆæ™‚é–“**ï¼š{datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
        **ç³»çµ±**ï¼š{Config.APP_NAME}
        
        æ³¨æ„äº‹é …ï¼š
        1. æ‰€æœ‰å…§å®¹å¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡
        2. è¶…é€£çµæ ¼å¼ï¼š[æ¨™é¡Œ](ç¶²å€)
        3. å»é™¤é‡è¤‡è³‡è¨Š
        4. ä¿æŒå°ˆæ¥­ä¸”æ˜“è®€
        5. å¦‚æœæ²’æœ‰æ‰¾åˆ°ç›¸é—œæ–°èï¼Œè«‹æ˜ç¢ºèªªæ˜
        """
        
        try:
            # ä½¿ç”¨ Agent åŸ·è¡Œåˆ†æ
            response = self.agent.run(analysis_prompt)
            
            # æå– Markdown å…§å®¹
            if hasattr(response, 'content'):
                markdown_report = response.content
            else:
                markdown_report = str(response)
            
            # æå–çµæ§‹åŒ–æ–°èæ•¸æ“š
            structured_news = self._extract_structured_data(markdown_report, content, query)
            
            print("âœ… Analyst Agent åˆ†æå®Œæˆ")
            return markdown_report, structured_news
            
        except Exception as e:
            print(f"âŒ Analyst Agent åˆ†æå¤±æ•—: {str(e)}")
            # è¿”å›éŒ¯èª¤å ±å‘Š
            error_report = f"""
# å ±å‘Šç”Ÿæˆå¤±æ•—

## éŒ¯èª¤è³‡è¨Š
{str(e)}

## åŸå§‹æœå°‹æŸ¥è©¢
{query}

è«‹æª¢æŸ¥ç³»çµ±è¨­å®šä¸¦é‡è©¦ã€‚
"""
            return error_report, []
    
    def _extract_structured_data(self, markdown_report: str, raw_content: str, query: str) -> List[Dict[str, str]]:
        """
        å¾ Markdown å ±å‘Šå’ŒåŸå§‹å…§å®¹ä¸­æå–çµæ§‹åŒ–æ–°èæ•¸æ“š
        
        å„ªå…ˆå¾ Markdown å ±å‘Šä¸­æå–ï¼Œå› ç‚ºå…¶ä¸­çš„æ¨™é¡Œå·²ç¶“è¢«ç¿»è­¯æˆä¸­æ–‡
        
        Args:
            markdown_report: Markdown æ ¼å¼çš„å ±å‘Šï¼ˆåŒ…å«å·²ç¿»è­¯çš„ä¸­æ–‡æ¨™é¡Œï¼‰
            raw_content: ä¾†è‡ªæœå°‹çš„åŸå§‹å…§å®¹
            query: æœå°‹æŸ¥è©¢ï¼ˆä½œç‚ºé—œéµå­—ï¼‰
            
        Returns:
            List[Dict]: çµæ§‹åŒ–çš„æ–°èåˆ—è¡¨
        """
        structured_news = []
        
        try:
            # å„ªå…ˆå¾ Markdown å ±å‘Šä¸­æå–ï¼ˆæ¨™é¡Œå·²ç¿»è­¯æˆä¸­æ–‡ï¼‰
            print("ğŸ“ å¾ Markdown å ±å‘Šä¸­æå–çµæ§‹åŒ–æ•¸æ“šï¼ˆå«ä¸­æ–‡æ¨™é¡Œï¼‰...")
            structured_news = self._extract_from_markdown(markdown_report, query)
            
            # å¦‚æœ Markdown æå–å¤±æ•—ï¼Œæ‰å˜—è©¦å¾ JSON è§£æ
            if not structured_news:
                print("âš ï¸ Markdown æå–å¤±æ•—ï¼Œå˜—è©¦å¾ JSON è§£æ...")
                json_match = re.search(r'```json\s*(\{.*?\})\s*```', raw_content, re.DOTALL)
                if json_match:
                    json_data = json.loads(json_match.group(1))
                    results = json_data.get('results', [])
                    
                    for result in results:
                        # æå–åœ‹å®¶è³‡è¨Šï¼ˆå¾ä¾†æºæˆ–æ¨™é¡Œä¸­ï¼‰
                        country = self._extract_country(
                            result.get('title', ''),
                            result.get('source', ''),
                            result.get('summary', '')
                        )
                        
                        structured_news.append({
                            'æ–°èæ¨™é¡Œï¼ˆä¸­æ–‡ï¼‰': result.get('title', ''),
                            'ä¾†æºåœ‹å®¶': country,
                            'é—œéµå­—': query,
                            'ä¾†æºç¶²ç«™é€£çµ': result.get('url', ''),
                            'ç™¼å¸ƒæ—¥æœŸ': result.get('date', ''),
                            'ä¾†æº': result.get('source', '')
                        })
        
        except Exception as e:
            print(f"âš ï¸ çµæ§‹åŒ–æ•¸æ“šæå–å¤±æ•—: {str(e)}")
            # ä½œç‚ºå¾Œå‚™ï¼Œå†æ¬¡å˜—è©¦å¾ Markdown ä¸­æå–
            structured_news = self._extract_from_markdown(markdown_report, query)
        
        if structured_news:
            print(f"âœ… æˆåŠŸæå– {len(structured_news)} å‰‡æ–°èï¼ˆæ¨™é¡Œå·²ç‚ºä¸­æ–‡ï¼‰")
        else:
            print("âš ï¸ æœªèƒ½æå–åˆ°ä»»ä½•æ–°èæ•¸æ“š")
        
        return structured_news
    
    def _extract_country(self, title: str, source: str, summary: str) -> str:
        """å¾æ–‡æœ¬ä¸­æå–åœ‹å®¶è³‡è¨Š"""
        text = f"{title} {source} {summary}".lower()
        
        countries = {
            'singapore': 'æ–°åŠ å¡',
            'malaysia': 'é¦¬ä¾†è¥¿äº',
            'thailand': 'æ³°åœ‹',
            'indonesia': 'å°å°¼',
            'vietnam': 'è¶Šå—',
            'philippines': 'è²å¾‹è³“',
            'æ–°åŠ å¡': 'æ–°åŠ å¡',
            'é¦¬ä¾†è¥¿äº': 'é¦¬ä¾†è¥¿äº',
            'æ³°åœ‹': 'æ³°åœ‹',
            'å°å°¼': 'å°å°¼',
            'è¶Šå—': 'è¶Šå—',
            'è²å¾‹è³“': 'è²å¾‹è³“'
        }
        
        for key, value in countries.items():
            if key in text:
                return value
        
        return 'æ±å—äº'
    
    def _extract_from_markdown(self, markdown_report: str, query: str) -> List[Dict[str, str]]:
        """å¾ Markdown å ±å‘Šä¸­æå–æ–°èè³‡è¨Š"""
        structured_news = []
        
        # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼åŒ¹é…æ–°èæ¨™é¡Œå’Œç›¸é—œè³‡è¨Š
        news_pattern = r'###\s+\d+\.\s+(.*?)\n(.*?)(?=###|\Z)'
        matches = re.findall(news_pattern, markdown_report, re.DOTALL)
        
        for title, content in matches:
            title = title.strip()
            
            # æå–ä¾†æºå’Œç¶²å€
            source_match = re.search(r'\*\*ä¾†æº\*\*[ï¼š:]\s*\[?(.*?)\]?\(?(https?://[^\s\)]+)', content)
            source = ''
            url = ''
            if source_match:
                source = source_match.group(1).strip()
                url = source_match.group(2).strip()
            else:
                # å˜—è©¦å¦ä¸€ç¨®æ ¼å¼
                url_match = re.search(r'(https?://[^\s\)]+)', content)
                if url_match:
                    url = url_match.group(1).strip()
            
            # æå–æ—¥æœŸ - æ”¹é€²çš„æ—¥æœŸæå–é‚è¼¯
            date = ''
            # é¦–å…ˆå˜—è©¦åŒ¹é… "**æ—¥æœŸ**ï¼šYYYY-MM-DD" æ ¼å¼
            date_match = re.search(r'\*\*æ—¥æœŸ\*\*[ï¼š:]\s*([^\n*]+)', content)
            if date_match:
                date = date_match.group(1).strip()
            else:
                # å˜—è©¦åŒ¹é…å…¶ä»–å¸¸è¦‹æ—¥æœŸæ ¼å¼
                # æ ¼å¼å¦‚ï¼š2025-10-13, 2025/10/13, 2025.10.13
                date_pattern = r'(\d{4}[-/\.]\d{1,2}[-/\.]\d{1,2})'
                date_match2 = re.search(date_pattern, content)
                if date_match2:
                    date = date_match2.group(1)
                else:
                    # å˜—è©¦ä¸­æ–‡æ—¥æœŸæ ¼å¼ï¼š2025å¹´10æœˆ13æ—¥
                    date_pattern_cn = r'(\d{4}å¹´\d{1,2}æœˆ\d{1,2}æ—¥)'
                    date_match3 = re.search(date_pattern_cn, content)
                    if date_match3:
                        date = date_match3.group(1)
            
            # æå–æ‘˜è¦ - æ”¹é€²çš„æ­£å‰‡è¡¨é”å¼ï¼Œæ”¯æ´å¤šè¡Œå…§å®¹
            summary = ''
            # å˜—è©¦åŒ¹é…æ‘˜è¦å…§å®¹ï¼Œç›´åˆ°é‡åˆ°ä¸‹ä¸€å€‹ç²—é«”é …ç›®æˆ–çµæŸ
            summary_match = re.search(r'\*\*æ‘˜è¦\*\*[ï¼š:]\s*([^\n]*(?:\n(?!\s*[-\*]\s*\*\*)[^\n]*)*)', content, re.DOTALL)
            if summary_match:
                summary = summary_match.group(1).strip()
            
            # æå–é‡é»åˆ†æ - æ”¹é€²çš„æ­£å‰‡è¡¨é”å¼ï¼Œæ”¯æ´å¤šè¡Œå’Œæ¢åˆ—å¼å…§å®¹
            analysis = ''
            # å˜—è©¦åŒ¹é…é‡é»åˆ†æå…§å®¹ï¼Œç›´åˆ°é‡åˆ°ä¸‹ä¸€å€‹æ¨™é¡Œæˆ–çµæŸ
            analysis_match = re.search(r'\*\*é‡é»åˆ†æ\*\*[ï¼š:]\s*([^\n]*(?:\n(?!\s*###|\s*##|\s*[-\*]\s*\*\*(?!.*åˆ†æ))[^\n]*)*)', content, re.DOTALL)
            if analysis_match:
                analysis = analysis_match.group(1).strip()
            
            # æå–åœ‹å®¶
            country = self._extract_country(title, source, content)
            
            structured_news.append({
                'æ–°èæ¨™é¡Œï¼ˆä¸­æ–‡ï¼‰': title,
                'ä¾†æºåœ‹å®¶': country,
                'é—œéµå­—': query,
                'ä¾†æºç¶²ç«™é€£çµ': url,
                'ç™¼å¸ƒæ—¥æœŸ': date,
                'æ‘˜è¦': summary,
                'é‡é»åˆ†æ': analysis,
                'ä¾†æº': source
            })
        
        return structured_news


if __name__ == "__main__":
    # æ¸¬è©¦ Analyst Agent
    agent = AnalystAgent()
    
    # æ¨¡æ“¬æœå°‹çµæœ
    mock_results = {
        "status": "success",
        "query": "æ–°åŠ å¡è‚¡å¸‚å‹•æ…‹",
        "content": "æ¸¬è©¦å…§å®¹ï¼šæ–°åŠ å¡æµ·å³½æ™‚å ±æŒ‡æ•¸ä¸Šæ¼²..."
    }
    
    report = agent.analyze(mock_results)
    print(report)
